{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align='center'>Data preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our Data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-efe3f88977f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unprocessed_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "Dataset = pd.read_csv('unprocessed_data.csv')\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seperating the data to inputs and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seperating the features \"inputs\"\n",
    "features_matrix = Dataset.iloc[:,:-1].values #passing the data to a numpy array called features_matrix\n",
    "features_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seperating the output -> \"purchased or not\"\n",
    "goal_vector = Dataset.iloc[:,-1].values\n",
    "goal_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling the missing data by replacing it with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the Imputer module which can handle the missing data\n",
    "from sklearn.preprocessing import Imputer\n",
    "# creating a new object\n",
    "imputer = Imputer(missing_values='NaN', strategy='mean',axis=0) #we want to replace a row -> axis=0 , with it's mean -> strategy='mean'\n",
    "features_matrix[:, 1:3] = imputer.fit_transform(features_matrix[:, 1:3])#apply changes to all rows and cols from 1 to 3 \n",
    "features_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## after all in training a model we must use number so transforming a categorical data to numbers is an important step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 44.0, 72000.0],\n",
       "       [2, 27.0, 48000.0],\n",
       "       [1, 30.0, 54000.0],\n",
       "       [2, 38.0, 61000.0],\n",
       "       [1, 40.0, 63777.77777777778],\n",
       "       [0, 35.0, 58000.0],\n",
       "       [2, 38.77777777777778, 52000.0],\n",
       "       [0, 48.0, 79000.0],\n",
       "       [1, 50.0, 83000.0],\n",
       "       [0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder #importing LabelEncoder class \n",
    "encoder = LabelEncoder() #creating a new object\n",
    "features_matrix[:, 0] = encoder.fit_transform(features_matrix[:, 0]) #transforming the categorical data to numbers\n",
    "features_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# don't forget to transform the output if it's a boolean one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_vector = encoder.fit_transform(goal_vector)\n",
    "goal_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in Dealing with numbers \"2\" is greater than \"0\" which might affect the model as it will be more biased towards \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.40000000e+01,\n",
       "        7.20000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.70000000e+01,\n",
       "        4.80000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.00000000e+01,\n",
       "        5.40000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n",
       "        6.10000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n",
       "        6.37777778e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.50000000e+01,\n",
       "        5.80000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.87777778e+01,\n",
       "        5.20000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n",
       "        7.90000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.00000000e+01,\n",
       "        8.30000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n",
       "        6.70000000e+04]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the oneHotEncoder class\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oneHotEncoder = OneHotEncoder(categorical_features=[0]) #creating a new object and sending the targeted data to it\n",
    "features_matrix = oneHotEncoder.fit_transform(features_matrix).toarray()#transforming numbers\n",
    "features_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# think about training The model \n",
    "\n",
    "## we must have a training set and a test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "2\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_matrix, goal_vector, train_size = 0.8, random_state = 0)\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(features_matrix))\n",
    "# see the size percentage !\n",
    "# note :\n",
    "## the random state just to have the same result each time you run\n",
    "## the train size is changable and it depend on several things[the data size, the problem itself, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a large diversity in numbers leads to slowing down the computation \n",
    "## it's better to scale your Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before scalling, max is 79000 and min is 0\n",
      "after scalling, max is 2 and min is -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  2.64575131, -0.77459667,  0.26306757,  0.12381479],\n",
       "       [ 1.        , -0.37796447, -0.77459667, -0.25350148,  0.46175632],\n",
       "       [-1.        , -0.37796447,  1.29099445, -1.97539832, -1.53093341],\n",
       "       [-1.        , -0.37796447,  1.29099445,  0.05261351, -1.11141978],\n",
       "       [ 1.        , -0.37796447, -0.77459667,  1.64058505,  1.7202972 ],\n",
       "       [-1.        , -0.37796447,  1.29099445, -0.0813118 , -0.16751412],\n",
       "       [ 1.        , -0.37796447, -0.77459667,  0.95182631,  0.98614835],\n",
       "       [ 1.        , -0.37796447, -0.77459667, -0.59788085, -0.48214934]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the library we need from our beloved sklearn !\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# take a look how the values was before and after the scalling \n",
    "print('before scalling, max is %d and min is %d'%(np.max(x_train), np.min(x_train)))\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "print('after scalling, max is %d and min is %d'%(np.max(x_train), np.min(x_train)))\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(x_train)\n",
    "X_scaled\n",
    "X_scaled.mean(axis=0) # mean is zero\n",
    "X_scaled.std(axis=0) # variance is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the data to a specific range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  1.        , -1.        ,  0.23809524,  0.01792115],\n",
       "       [ 1.        , -1.        , -1.        , -0.04761905,  0.22580645],\n",
       "       [-1.        , -1.        ,  1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        ,  1.        ,  0.12169312, -0.74193548],\n",
       "       [ 1.        , -1.        , -1.        ,  1.        ,  1.        ],\n",
       "       [-1.        , -1.        ,  1.        ,  0.04761905, -0.16129032],\n",
       "       [ 1.        , -1.        , -1.        ,  0.61904762,  0.5483871 ],\n",
       "       [ 1.        , -1.        , -1.        , -0.23809524, -0.35483871]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1)) #setting the range\n",
    "X_train_minmax = min_max_scaler.fit_transform(x_train)\n",
    "X_train_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 1.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 1., 0.],\n",
       "       [1., 0., 0., 1., 1.],\n",
       "       [0., 0., 1., 1., 0.],\n",
       "       [1., 0., 0., 1., 1.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = preprocessing.Binarizer().fit(X_train_minmax)  # fit does nothing\n",
    "binarizer.transform(X_train_minmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
